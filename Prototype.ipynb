{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "protective-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from functools import reduce\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-channel",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "raised-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 300\n",
    "vocab_size = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "exterior-orlando",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "df['sentiment'] = (df['sentiment'] == 'positive').astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "earlier-opening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average word count: 231.15694\n"
     ]
    }
   ],
   "source": [
    "print(f\"average word count: {np.mean(df['review'].apply(lambda x: len(x.split())))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pressed-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean a string and get the vocab words from it\n",
    "def get_words(string):\n",
    "    string = string.lower().replace('<br />', ' ') # <br /> tags frequently appear, remove them\n",
    "    return re.findall(r'[a-z]+', string)\n",
    "\n",
    "# create and clean the vocabulary\n",
    "text_corpus = ' '.join(df['review'])\n",
    "words = get_words(text_corpus)\n",
    "\n",
    "# take the x most common words, otherwise we get a vocab of 100000\n",
    "word_counts = Counter(words)\n",
    "words = sorted(word_counts.items(), reverse=True, key=lambda x: x[1])[:vocab_size-5]\n",
    "words = list(list(zip(*words))[0]) # remove the counts\n",
    "words = ['<UNK>', '<PAD>', '<START>', '<END>', '<MASK>'] + words # add the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "minor-verification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique words: 20000\n"
     ]
    }
   ],
   "source": [
    "# create the dictionaries to store the vocab\n",
    "vocab_idx = {}\n",
    "idx_vocab = {}\n",
    "for i, word in enumerate(words):\n",
    "    if word not in vocab_idx:\n",
    "        vocab_idx[word] = i\n",
    "        idx_vocab[i] = word\n",
    "print(f\"number of unique words: {len(vocab_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dimensional-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a string to a list of indexes of its words\n",
    "# also add start and end tokens along with left padding\n",
    "def string_to_idxs(string):\n",
    "    idxs = list(map(lambda x: vocab_idx[x] if x in vocab_idx else 0, get_words(string)))\n",
    "    idxs = [2] + idxs[-(batch_size-2):] + [3] # crop to the batch_size and add the start and end tokens\n",
    "    padding = np.zeros((batch_size - len(idxs))) + 1\n",
    "    idxs = np.concatenate([padding, idxs]).astype(int)\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "racial-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_string(idxes):\n",
    "    return ' '.join(list(map(lambda x: idx_vocab[x], idxes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "broken-victor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [2, 33, 3177, 36, 29, 208, 18, 14, 10, 617, 51...\n",
       "1        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "2        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "3        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "4        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "                               ...                        \n",
       "49995    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "49996    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "49997    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "49998    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "49999    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "Name: idxed_review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a column that represents reviews a list of the words' indexes in the vocab\n",
    "df['idxed_review'] = df['review'].apply(string_to_idxs)\n",
    "df['idxed_review']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-killing",
   "metadata": {},
   "source": [
    "#### Build training and test set\n",
    "Training set has no closures and is a language modelling task\n",
    "\n",
    "Test set has the closures and is a classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "funded-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the review column into a multi dimensional array\n",
    "review_array = np.concatenate(df['idxed_review']).reshape(df.shape[0], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "restricted-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(review_array, np.array(df['sentiment']), test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "expensive-tackle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,    1,    1, ...,   16,    3,    1],\n",
       "       [   1,    1,    1, ...,   11,    3,    1],\n",
       "       [   7,  174,   54, ...,  300,    3,    1],\n",
       "       ...,\n",
       "       [   1,    1,    1, ..., 1703,    3,    1],\n",
       "       [ 102,  119,   24, ...,  120,    3,    1],\n",
       "       [ 240,  323,   26, ...,   59,    3,    1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the label for each word is the next word in the seqeunce, we also add a pad token at the end to keep the dimensions the same\n",
    "y_train = np.concatenate([X_train[:, 1:], np.ones((X_train.shape[0], 1)).astype(int)], axis=1)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "north-handling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,    1,    1, ...,  404,   16,    3],\n",
       "       [   1,    1,    1, ...,  107,   11,    3],\n",
       "       [   2,    7,  174, ...,    6,  300,    3],\n",
       "       ...,\n",
       "       [   1,    1,    1, ...,    6, 1703,    3],\n",
       "       [   2,  102,  119, ...,   26,  120,    3],\n",
       "       [   2,  240,  323, ...,   72,   59,    3]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-killer",
   "metadata": {},
   "source": [
    "### Model Building\n",
    "- First train an LSTM as a language model, then have it solve closures to get the predictions\n",
    "- Because the data would be too large to fit in memory if we converted it to one hot, we have to instead train using a generator (takes integers representing words and outputs a one hot vector\n",
    "- Clozure to start with: \"X + Overall this movie was (poor/great)\"  (figure out how to do Bidirectional LSTM without it just predicting \\<MASK\\> later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "organized-webmaster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, TimeDistributed, Dropout\n",
    "tf.config.list_physical_devices('GPU') # check gpu is in use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "instructional-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator class, it yields one review and its labels at a time\n",
    "class SampleSequence(tf.keras.utils.Sequence): # extend Seqeunce so that we can use multiprocessing\n",
    "    def __init__(self, X_train):\n",
    "        self.X = X_train\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "        \n",
    "    # get item at the index specified\n",
    "    def __getitem__(self, idx):\n",
    "        # the pad_token is used for creating the labels\n",
    "        pad_token = np.zeros((1, vocab_size))\n",
    "        pad_token[0, 1] = 1\n",
    "        \n",
    "        x_sample = self.X[idx, :].reshape(1, batch_size) # the embedding layer automatically handles integers\n",
    "        y_sample = np.zeros((batch_size, vocab_size)) # the labels need to be manually converted to one hot\n",
    "        for i in range(batch_size - 1):\n",
    "            y_sample[i, self.X[idx, i+1]] = 1  # the label at step1 is the word at step2\n",
    "        y_sample[-1, :] = pad_token # add the pad token for the 300th step's label\n",
    "        y_sample = y_sample.reshape(1, batch_size, vocab_size)\n",
    "            \n",
    "        return (x_sample, y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "prerequisite-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same thing but with a tensorflow dataset implementation, this allows parralelization \n",
    "# first define the mapping function to convert a tensor of X_train into an X, y sample\n",
    "pad_token = np.zeros((1, vocab_size))\n",
    "pad_token[0, 1] = 1\n",
    "pad_token = tf.constant(pad_token, dtype='float32')\n",
    "def text_to_sample(x_tensor): # takes a single sample and converts it to input text and ouput labels\n",
    "    y_one_hot = tf.one_hot(x_tensor, vocab_size, axis=-1) # axos=-1 means we get a tensor of shape (features, vocab_size)\n",
    "    y_one_hot = y_one_hot[1:, :] # shift back one\n",
    "    y_one_hot = tf.concat([y_one_hot, pad_token], axis=0) # add pad token at the end \n",
    "    x_tensor = tf.reshape(x_tensor, [1, batch_size])\n",
    "    return (x_tensor, y_one_hot)\n",
    "\n",
    "# create training Dataset, apply the function to create the pipeline\n",
    "def create_dataset(data):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "    dataset = dataset.map(text_to_sample)\n",
    "    return dataset\n",
    "\n",
    "training = create_dataset(X_train)\n",
    "testing = create_dataset(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model, eventually this should be bi-directional\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 500, input_length=batch_size))\n",
    "model.add(LSTM(500, return_sequences=True,\n",
    "              activation='tanh', recurrent_activation='sigmoid',\n",
    "              dropout=0.2, recurrent_dropout=0))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(TimeDistributed(Dense(20000, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', metrics=['categorical_accuracy'],\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "handy-religious",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 45000 steps, validate for 5000 steps\n",
      "Epoch 1/10\n",
      "45000/45000 [==============================] - 3875s 86ms/step - loss: 3.7736 - categorical_accuracy: 0.4407 - val_loss: 3.5183 - val_categorical_accuracy: 0.4589\n",
      "Epoch 2/10\n",
      "45000/45000 [==============================] - 3199s 71ms/step - loss: 3.4452 - categorical_accuracy: 0.4652 - val_loss: 3.3598 - val_categorical_accuracy: 0.4714\n",
      "Epoch 3/10\n",
      "45000/45000 [==============================] - 3202s 71ms/step - loss: 3.3348 - categorical_accuracy: 0.4737 - val_loss: 3.2772 - val_categorical_accuracy: 0.4782\n",
      "Epoch 4/10\n",
      "45000/45000 [==============================] - 3199s 71ms/step - loss: 3.2688 - categorical_accuracy: 0.4790 - val_loss: 3.2256 - val_categorical_accuracy: 0.4826\n",
      "Epoch 5/10\n",
      "45000/45000 [==============================] - 3223s 72ms/step - loss: 3.2247 - categorical_accuracy: 0.4825 - val_loss: 3.1918 - val_categorical_accuracy: 0.4853\n",
      "Epoch 6/10\n",
      "45000/45000 [==============================] - 3314s 74ms/step - loss: 3.1918 - categorical_accuracy: 0.4851 - val_loss: 3.1657 - val_categorical_accuracy: 0.4876\n",
      "Epoch 7/10\n",
      "45000/45000 [==============================] - 3348s 74ms/step - loss: 3.1658 - categorical_accuracy: 0.4873 - val_loss: 3.1470 - val_categorical_accuracy: 0.4895\n",
      "Epoch 8/10\n",
      "45000/45000 [==============================] - 3355s 75ms/step - loss: 3.1448 - categorical_accuracy: 0.4891 - val_loss: 3.1326 - val_categorical_accuracy: 0.4906\n",
      "Epoch 9/10\n",
      "45000/45000 [==============================] - 3348s 74ms/step - loss: 3.1268 - categorical_accuracy: 0.4905 - val_loss: 3.1216 - val_categorical_accuracy: 0.4916\n",
      "Epoch 10/10\n",
      "45000/45000 [==============================] - 3382s 75ms/step - loss: 3.1119 - categorical_accuracy: 0.4916 - val_loss: 3.1117 - val_categorical_accuracy: 0.4924\n"
     ]
    }
   ],
   "source": [
    "# With CUDNN implementation it runs faster, does take a lot of time to begin though\n",
    "history = model.fit(x=training, validation_data=testing, epochs=10, \n",
    "                    use_multiprocessing=True, # allows multiple cpu cores to work on generating data samples at once\n",
    "                    max_queue_size=50, # size of the queue of training items the cpu will create\n",
    "                    workers=4) # number of processes that will generate items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "educational-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"language_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fixed-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"language_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "nervous-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(create_dataset(X_test[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "median-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = X_test[:1000, 1:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bizarre-senior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> winchester is a great story and that s what i like about it it s not your everyday western it uses a rifle which passes hands from various characters as a mechanism for telling the story about these people rock hudson plays an indian chief jimmy stewart plays a great leading man with heart and strength and shelly winters plays a gal who has to cope with the realities of her husband and the wild west it s important to note for those politically correct types they kill a lot of indians in this movie without remorse by today s standards it s still pretty violent but it s a great story and worth watching enjoy <END>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = 2\n",
    "index_to_string(X_test[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aggressive-infection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> this is a great film about a is not it think about the is is a a typical life but s the lot and is for down the <UNK> and the <UNK> of the the story of the people who hudson is a <UNK> <UNK> who stewart and a <UNK> role man who a and his and his <UNK> is a role who is a be with the <UNK> of the life and her <UNK> <UNK> the s a to see that the who correct the of are the man of people and the movie but any and the s standards the is a a good and it s not very film and a watching for <END> <PAD>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_string(np.argmax(preds[item], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "supported-thermal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21,  6,  5, 12,  9, 26, 11,  7, 43, 20, 22, 14, 18, 15, 36, 13, 10,\n",
       "       51, 32, 24], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.flip(np.argsort(preds[50, 100]))[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-cisco",
   "metadata": {},
   "source": [
    "### Closure Creation \n",
    "Analyse performance on the test set given by solving closure problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "informational-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "closures = np.zeros(X_test.shape, dtype='int')\n",
    "prompt = \"Overall the movie was\"\n",
    "for i in range(X_test.shape[0]):\n",
    "    review = index_to_string(X_test[i, :-1]).replace('<PAD> ', '') # convert to string, removing the <END> and <PAD> tokens\n",
    "    closures[i, :] = string_to_idxs(review + \" \" + prompt)\n",
    "closures = create_dataset(closures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "loose-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to perform prediction in steps as otherwise the output doesn't fit in memory\n",
    "def generator_predict(closures):\n",
    "    for data in closures:\n",
    "        yield model.predict(data)[0, -1, :] # take the prediction for the last word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "disturbed-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the predicted probabilities\n",
    "pred_probas = [] # the probability that the next word is \"Good\" if it must by Good or Bad\n",
    "for i, pred in enumerate(generator_predict(closures)):\n",
    "    good_prob = pred[vocab_idx['good']] # great\n",
    "    bad_prob = pred[vocab_idx['bad']]   # poor\n",
    "    total = good_prob + bad_prob\n",
    "    pred_probas.append(good_prob/(good_prob + bad_prob)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "supported-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the cutoff that gives the highest accuracy\n",
    "pred_probas = np.array(pred_probas)\n",
    "c_range = np.arange(0, 1, 0.001)\n",
    "accuracies = []\n",
    "for cutoff in c_range:\n",
    "    class_preds = (pred_probas > cutoff).astype(int)\n",
    "    accuracies.append(accuracy_score(y_test, class_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bacterial-convenience",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x140108dc148>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(c_range, accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-crossing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
