{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4f70fcb-4ddc-4373-b01d-6199057beb48",
   "metadata": {},
   "source": [
    "Performs few-shot learning by prompting a GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cc3e552-63e4-48f6-92c5-5161fefc5373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce501b5a-f260-4abc-89c0-d3a44c820c7f",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "314ed453-2695-412a-9cc4-e73aed6f1972",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e1ba918-c84f-4294-8edd-e81b7c617e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "df['sentiment'] = (df['sentiment'] == 'positive').astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47bee21b-f3fa-4a01-8907-b8e0c85aee47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        307\n",
       "1        162\n",
       "2        166\n",
       "3        138\n",
       "4        230\n",
       "        ... \n",
       "49995    194\n",
       "49996    112\n",
       "49997    230\n",
       "49998    212\n",
       "49999    129\n",
       "Name: review, Length: 50000, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a37d8308-ead5-48ee-8046-7174c401555f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average word count: 231.15694\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['review'].apply(lambda x: min(len(x.split()), 1000)), bins=20)\n",
    "plt.ylabel(\"Number of texts\")\n",
    "plt.xlabel(\"Word count\")\n",
    "print(f\"average word count: {np.mean(df['review'].apply(lambda x: len(x.split())))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f23d60b-256c-463b-b324-f1615b3ab0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a train-val-test split 80%-10%-10%\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(df['review']), np.array(df['sentiment']), test_size=0.2)\n",
    "X_val, X_test, y_val, t_test = train_test_split(X_test, y_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a0ccec-df85-4bb4-84d3-71611c0ccb56",
   "metadata": {},
   "source": [
    "# GPT2 Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "944e90fc-2a50-41fd-ab4a-3bdc3210c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadã€€GPT, BERT and support materials from huggingface\n",
    "# requires pip install transformers\n",
    "# if in jupyter notebook see here and you get an error mention ipython widgets see here: \n",
    "# https://stackoverflow.com/questions/53247985/tqdm-4-28-1-in-jupyter-notebook-intprogress-not-found-please-update-jupyter-an\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03a2618c-5234-4df7-adf0-0aeb90ebcd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the models\n",
    "# Documentation for GPT: https://huggingface.co/transformers/model_doc/gpt2.html#gpt2lmheadmodel\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2621d1bd-c2d1-400d-932e-715815280012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dataset class for language model fine-tuning, it's a generator so we don't have to store the entire dataset in memory\n",
    "class GPT2Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, txt_list, tokenizer, max_length=max_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "\n",
    "        # Encode all the text, padding and truncuating it along with adding attention masks to get the sequence length the same across all samples\n",
    "        for txt in txt_list:\n",
    "            encodings_dict = tokenizer.encode_plus(txt, truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "            self.input_ids.append(encodings_dict['input_ids'])\n",
    "            self.attn_masks.append(encodings_dict['attention_mask'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # The tutorial use a dictionary format that also stores labels \n",
    "        return_dict = {\"input_ids\": torch.tensor(self.input_ids[idx]),\n",
    "                       \"attention_mask\": torch.tensor(self.attn_masks[idx]), \n",
    "                       \"labels\": torch.tensor(self.input_ids[idx])} \n",
    "        return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12b29955-cfdc-464a-9253-0eee67524827",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
    "train_dataset = GPT2Dataset(X_train, gpt_tokenizer)\n",
    "val_dataset = GPT2Dataset(X_val, gpt_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78855ca2-a24b-4452-b1ff-d9891f3c0e4c",
   "metadata": {},
   "source": [
    "Do fine tuning of the gpt_model using the hugging face out of the box trainer https://huggingface.co/transformers/custom_datasets.html#fine-tuning-with-trainerfrom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "134989b8-2794-4412-9ea0-2a77d48b293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"gpt_model.model\"):\n",
    "    gpt_model = torch.load(\"gpt_model.model\")\n",
    "else:\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='gpt_finetuning',     # output directory\n",
    "        num_train_epochs=1,              # total number of training epochs (1 is enough to get very low perplexity and perplexity increases at 2)\n",
    "        per_device_train_batch_size=4,  # batch size per device during training\n",
    "        per_device_eval_batch_size=4,   # batch size for evaluation\n",
    "        warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.001,               # strength of weight decay\n",
    "        logging_dir='gpt_finetuning_logs',            # directory for storing logs\n",
    "        logging_steps=100,\n",
    "\n",
    "        # Increase the betas as the batch size is quite small so updates are very stochastic\n",
    "        adam_beta1=0.95, \n",
    "        adam_beta2=0.9995,\n",
    "        learning_rate=1e-5\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=gpt_model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "        args=training_args,                  # training arguments, defined above\n",
    "        train_dataset=train_dataset,         # training dataset\n",
    "        eval_dataset=val_dataset             # evaluation dataset\n",
    "    )\n",
    "\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab400612-98a3-4f41-b0a8-803963bff92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gpt_model, \"gpt_model.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f6c92a-403f-43e8-8312-52edd172e04c",
   "metadata": {},
   "source": [
    "# Testing Prompt Classification\n",
    "Perform classification by adding the prompt \"In summary the movie was\" to the end of a review and classifying based on the probability of \"Good\" v.s. \"Bad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff8ccab5-9422-4210-ab4e-32a2b7c8c076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0, 1, 2][-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79eaf6bd-798c-4a9c-b593-1fa159c6caec",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4bbc1e49-7a01-48ed-9896-3bc2dfeb761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new model class, takes a list of strings as input and outputs the binary classification probability p(good | review) / (p(good | review) + p(bad | review))\n",
    "class gpt_prompt(torch.nn.Module):\n",
    "    def __init__(self, gpt_model, tokenizer, prompt=\"in summary the movie was\", pos_token=\"good\", neg_token=\"bad\"):\n",
    "        super().__init__()\n",
    "        self.gpt = gpt_model.to(device)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.prompt = prompt\n",
    "        self.prompt_length = len(tokenizer.encode(prompt))\n",
    "        self.pos_token = tokenizer.encode(pos_token)[0]\n",
    "        self.neg_token = tokenizer.encode(neg_token)[0]\n",
    "        \n",
    "    def forward(self, sentences):\n",
    "        # Loop through and add prompts to the sentences, then perform prediction\n",
    "        preds = []\n",
    "        for string in sentences:\n",
    "            length = len(self.tokenizer.encode(string))\n",
    "            if length + self.prompt_length <= max_length:\n",
    "                encodings_dict = self.tokenizer.encode_plus(string + \" \" + self.prompt, truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "                prompt_end_idx = length + self.prompt_length - 1\n",
    "            else: # encode full sentence then replace the (truncated) end with the prompt\n",
    "                encodings_dict = self.tokenizer.encode_plus(string, truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "                encodings_dict[\"input_ids\"][-self.prompt_length:] = self.tokenizer.encode(self.prompt)\n",
    "                prompt_end_idx = max_length - 1\n",
    "            preds.append(self.predict(encodings_dict, prompt_end_idx))\n",
    "            # Tests\n",
    "            # print(self.tokenizer.decode(encodings_dict[\"input_ids\"]))\n",
    "            # print(prompt_end_idx, self.tokenizer.decode(encodings_dict[\"input_ids\"][prompt_end_idx]))\n",
    "            assert self.tokenizer.decode(encodings_dict[\"input_ids\"][prompt_end_idx]) != \"<|endoftext|>\", \"Prompt_end_idx points to a padding token not the prompt\"\n",
    "        return preds\n",
    "    \n",
    "    # given an encoded sentence + prompt and the end of the prompt return binary classification probability\n",
    "    def predict(self, encodings_dict, prompt_end_idx):\n",
    "        input_ids = torch.tensor([encodings_dict[\"input_ids\"]]).long().to(device)\n",
    "        attn_mask = torch.tensor([encodings_dict[\"attention_mask\"]]).long().to(device)\n",
    "        word_preds = self.gpt(input_ids, attention_mask=attn_mask)[\"logits\"][0, prompt_end_idx, :]\n",
    "        word_preds = torch.nn.functional.softmax(word_preds, dim=0)\n",
    "        return word_preds[self.pos_token]/(word_preds[self.pos_token] + word_preds[self.neg_token]), word_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c31ed1db-2953-474e-a246-98d48c3b1ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompted = gpt_prompt(gpt_model, gpt_tokenizer, prompt=\"All in all the movie was\", pos_token=\"good\", neg_token=\"poor\")\n",
    "prompted.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db324b1-eae1-482c-9e3a-cc2df12ae506",
   "metadata": {},
   "source": [
    "## An example\n",
    "Here we view the model's prediction for the following positive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d2ef3c22-0707-4b61-ad7e-981a4182a19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"The unlikely duo of Zero Mostel and Harry Belafonte team up to give us some interesting performances and subject matter in The Angel Levine. \n",
    "It's one interesting twist on the themes from It's A Wonderful Life.<br /><br />Zero is married to Ida Kaminsky and the two of them belong to a special class of elderly Jewish poor in New York.\n",
    "Mostel used to be a tailor and proud of his trade, but his back and arthritis have prevented him from working. Kaminsky is mostly bedridden. He's reduced to applying for welfare. \n",
    "In desperation like Jimmy Stewart, he cries out to God for some help.<br /><br />Now maybe if he had gotten someone like Henry Travers things might have worked out differently, \n",
    "but even Stewart had trouble accepting Travers. But Travers had one thing going for him, he was over 100 years off this mortal coil and all his ties to earthly things were gone.\n",
    "God sent Mostel something quite different, the recently deceased Harry Belafonte who should have at least been given some basic training for angels before being given an assignment.<br /><br />Belafonte\n",
    "hasn't accepted he's moved on from life, he's still got a lot of issues. He also has a wife, Gloria Foster, who doesn't know he's passed on, hit by a car right at the beginning of the film. \n",
    "You put his issues and Mostel's issues and you've got a good conflict, starting with the fact that Mostel can't believe in a black Jew named Levine.<br /><br />This was the farewell performance for \n",
    "Polish/Jewish actress Ida Kaminsky who got a nomination for Best Actress in The Shop on Main Street a few years back. The other prominent role here is that of Irish actor Milo O'Shea playing a nice \n",
    "Jewish doctor. Remembering O'Shea's brogue from The Verdict, I was really surprised to see and hear him carry off the part of the doctor.<br /><br />The Angel Levine raises some interesting and \n",
    "disturbing questions about faith and race in this society. It's brought to you by a stellar cast and of course created by acclaimed writer Bernard Malamud. Make sure to catch it when broadcast.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7e30b75c-b4d8-4d47-ad11-80939c6c7f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "474"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gpt_tokenizer.encode(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ff9d8d40-b9db-4f0a-bbd4-2094eb5badae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' a', ' very', ' great', ' an', ' the', ' so', ' just', ' one', ' nice', ' really', ' pretty', ' like', ' interesting', ' good', ' quite', ' wonderful', ' about', ' not', ',', ' funny', ' also', ' kind', ' well', ' fun', ' his', ' brilliant', ' amazing', ' excellent', ' memorable', ' beautiful', ' hilarious', ' such', ' more', ' touching', ' rather', ' enjoyable', ' almost', ' that', ' all', ' entertaining', ' fascinating', ' impressive', ' another', ' probably', ' as', ' much', ' superb', ' truly', ' painful', ' lovely', ' perfect', ' too', ' remarkable', ' to', ' fantastic', ' in', ' this', ' extremely', ' amusing', ' going', ' full', ' worth', ' somewhat', ' what', ' especially', ' done', ' surreal', ' way', ' only', ' something', ' fairly', ' better', ' delightful', ' enough', ' awesome', ' made', ' her', ' simply', ' even', ' pure', ' moving', ' bad', ' hard', ' mostly', ' actually', ' some', ' supposed', ' fine', ' no', ' particularly', ' incredible', ' meant', ' exciting', ' incredibly', ' bitters', ' nothing', ' over', ' by', ' still', ' special']\n",
      "Positive likelihood: tensor(0.8852, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    results = prompted.forward([review])\n",
    "    result = results[0][1].cpu().numpy()\n",
    "    r = list(np.argsort(result)[::-1][:100])\n",
    "    print([gpt_tokenizer.decode([x]) for x in r])\n",
    "    print(\"Positive likelihood:\", results[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de2cc71-85e6-4161-b3c0-2fcd28b8cdec",
   "metadata": {},
   "source": [
    "We can see the most likely words (near the start of the list)  are positive e.g. \"great\", \"excellent\", \"good\". Whereas negative words such as \"mediocre\" and \"boring\" are much lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "11c02887-73e5-4af1-b162-7c0deb9711fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4692123-0c81-4cd0-a400-3b31260eb981",
   "metadata": {},
   "source": [
    "## Accuracy evaluation and threshold tuning\n",
    "Here we find the optimal prediction threshold, as our positive token good has a higher base chance of appearing than bad which means with a threshold of 0.5 the model tends to predict all samples as positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2633d2b7-1480-4a97-830f-6ad1b51bd6da",
   "metadata": {},
   "source": [
    "# Few Shot Learning\n",
    "Now we see the affect of training the prompted model using only 10 labelled samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df65c810-fcc7-4083-872d-02d020f868ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
